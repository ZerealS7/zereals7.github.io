<!doctype html>
<html lang="en-us">
  <head>
    <title> // Zereal-宋致远技术博客</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.72.0" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75，minimum-scale=0.75, maximum-scale=0.75, user-scalable=no" />
    <meta name="author" content="Zereal" />
    <meta name="description" content="" />
    <meta name="referrer" content="never"/>
    <link rel="stylesheet" href="https://zereals7.github.io/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="【机器学习】 线性模型形式简单、易于建模。许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。此外，由于w直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。
线性回归
对离散属性，若属性间存在序的关系，可通过连续化将其转化为连续值例如二值属性.
均方误差有非常好的几何意义，它对应了常用的欧几里得距离。基于均方误差最小化来进行模型求解的方法称为最小二乘法。
线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线的欧氏距离之和最小。
决策树
决策树是一类常见的机器学习方法，以二分类任务为例，我们希望从给定巡礼那数据集学得一个模型用以对新示例进行分类。一般的，一颗决策树包含一个根结点、若干个内部结点和若干个叶结点。
决策树学习的目的是为了产生一颗泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的分而治之策略。
显然，决策树的生成是一个递归过程，在决策树算法中，有三种情况会导致递归返回。
、1.当前结点包含的样本全属于同一类别，无需划分。
2.当前属性集为空，或是所有样本在所有属性上取值相同，无法划分。
3.当前结点包含的样本集合为空，不能划分。
一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高。
**信得的纯度提升越大。
一般而言，信息增益越大，则意味着使用属性a来进行划分获得的纯度提升越大。
计算出最大的信息增益对应的属性可作为进行划分的。然后再以子节点最大信息增益对应的属性进行划分，最后可以得到决策树。
实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来不利影响，决策树算法不使用信息增益，而是使用增益率来选择最优划分属性。增益率准则对可取值较少的属性有所偏好，算法并不是直接选择增益率最大的候选划分属性，而是使用一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。
基尼指数
决策树使用基尼指数来选择划分属性
数据集D的纯度可用基尼值来度量。
基尼越小数据集D的纯度越高。我们再候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性。
剪枝处理
剪枝是决策树算法对付过拟合的主要手段，再决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得太好了，以至于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险。
【神经网络】 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。
神经网络中最基本的是神经元模型。生物神经网络这，每个神经元与其他神经元相连，当它兴奋时，就会向相连的神经元发送化学物质，从而改变这些神经元的电位。如果某神经元电位超过了一个阈值，那么它就会被激活，即兴奋起来，向其他神经元发送化学物质。
神经元接收到的总输入值将与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。
理想的激活函数是阶跃函数，它将输入值映射为输出值0或1，显然1对应神经元兴奋，0对应于神经元抑制。然而阶跃函数具有不连续、不光滑等不太好的性质。因此时常使用sigmod挤压函数来作为激活函数。。它把较大范围变化的输入值挤压到（0,1）输出值范围内，因此有时也称为挤压函数。
把许多个神经元按一定层次结构连接起来，就得到了神经网络。
只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，相互代入得到。
感知机与多层网络
感知机由两层神经元组成。输入层接收外界输入信号后传递给输出层，输出层是MP神经元，也称阈值逻辑单元。
感知机能容易地实现逻辑与或非运算。
更一般的，给定训练数据集，权重以及阈值可通过学习得到。
若感知机对训练样例的预测准确，则感知机不发生变化，否则将根据错误的程度进行权重调整。
要注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非常有限。
事实上与或非等问题都是线性可分问题。若两类模式是线性可分的，即存在一个超平面能将其分开。
感知机的学习过程一定会收敛，且求得适当的权向量。否则感知机学习过程将会发生震荡。
要解决非线性可分的问题，需考虑使用多层功能神经元。输出层与输入层之间的一层神经元被称为隐含层，隐含层和输出层神经元都具有激活函数的功能神经元。
更一般的，常见的神经网络是层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为多层前馈神经网络。
其中输入层神经元接收外界输入，隐层和输出层神经元对信号进行加工。最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。只需包含隐层即可称为多层网络，神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。换言之，神经网络学到的东西，蕴含在连接权与阈值中。
误差逆传播算法
多层网络的学习能力比单层感知机强的多。要训练多层网络，简单感知机学习规则显然不够，需要更为强大的学习算法。误差逆传播（BP）算法就是其中杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中，使用神经网络时，大多是在使用BP算法进行训练
值得指出的是，BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络。例如训练递归神经网络。但通常说BP网络时，一般是指用BP算法训练的多层前馈神经网络。
BP算法探秘
BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计。
BP算法基于梯度下降策略，以目标负梯度方向对参数进行调整。
学习率n控制算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。对于学习率即步长非常敏感。
不能保证全局最低，只能是局部最低。
BP算法基本工作流程
对每个训练样例 ，BP算法执行以下操作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直至产生输出层结果；然后计算输出层的误差，再将误差逆向传播至隐层神经元，最后根据隐层神经元误差来对连接权和阈值进行调整。该迭代过程循环进行，直到达到某些停止条件为止。例如训练误差已达到一个很小的值。
BP算法的目标是要最小化训练集D上的累积误差 损失函数
标准BP算法每次仅针对一个训练样例更新连接权和阈值。
累积BP算法和标准BP算法都很常用，一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现抵消现象。因此，为了达到同样的累积误差极小点，标准BP算法往往需要进行更多次数的迭代。
累积BP算法直接针对累积误差最小化，它在读取整个训练集D一遍后才对参数进行更新，一步下降会非常缓慢。这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显。
只需一个包含足够多神经元的隐层，多层前馈网络就能以任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠试错法调整。
正是由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两者策略常用来缓解BP网络的过拟合 。第一种策略是早停：将数据分为训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差。若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。
第二种策略是正则化，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。
全局最小与局部极小
若用E表示神经网络在训练集上的误差，则它显然是关于连接权和阈值的函数。此时，神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得E最小。
显然参数空间内梯度为0的点只要其误差函数值小于邻点的误差函数值，就是局部极小点。但却只会有一个全局最小值。
基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值。每次迭代中。我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索 最优解。若误差函数在当前点的梯度为0则已到局部极小，更新量将为0，这意味着参数的迭代更新在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小 。然而，如果误差具有多个局部极小，则不能保证找到的解是全局最小。对后一种情况，我们称参数陷入了局部极小，这不是我们所希望的。
现实任务中，人们常用一下策略试图跳出局部极小，从而进一步接近全局最小。
以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。"/>

    <meta property="og:title" content="" />
<meta property="og:description" content="【机器学习】 线性模型形式简单、易于建模。许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。此外，由于w直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。
线性回归
对离散属性，若属性间存在序的关系，可通过连续化将其转化为连续值例如二值属性.
均方误差有非常好的几何意义，它对应了常用的欧几里得距离。基于均方误差最小化来进行模型求解的方法称为最小二乘法。
线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线的欧氏距离之和最小。
决策树
决策树是一类常见的机器学习方法，以二分类任务为例，我们希望从给定巡礼那数据集学得一个模型用以对新示例进行分类。一般的，一颗决策树包含一个根结点、若干个内部结点和若干个叶结点。
决策树学习的目的是为了产生一颗泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的分而治之策略。
显然，决策树的生成是一个递归过程，在决策树算法中，有三种情况会导致递归返回。
、1.当前结点包含的样本全属于同一类别，无需划分。
2.当前属性集为空，或是所有样本在所有属性上取值相同，无法划分。
3.当前结点包含的样本集合为空，不能划分。
一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高。
**信得的纯度提升越大。
一般而言，信息增益越大，则意味着使用属性a来进行划分获得的纯度提升越大。
计算出最大的信息增益对应的属性可作为进行划分的。然后再以子节点最大信息增益对应的属性进行划分，最后可以得到决策树。
实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来不利影响，决策树算法不使用信息增益，而是使用增益率来选择最优划分属性。增益率准则对可取值较少的属性有所偏好，算法并不是直接选择增益率最大的候选划分属性，而是使用一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。
基尼指数
决策树使用基尼指数来选择划分属性
数据集D的纯度可用基尼值来度量。
基尼越小数据集D的纯度越高。我们再候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性。
剪枝处理
剪枝是决策树算法对付过拟合的主要手段，再决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得太好了，以至于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险。
【神经网络】 神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。
神经网络中最基本的是神经元模型。生物神经网络这，每个神经元与其他神经元相连，当它兴奋时，就会向相连的神经元发送化学物质，从而改变这些神经元的电位。如果某神经元电位超过了一个阈值，那么它就会被激活，即兴奋起来，向其他神经元发送化学物质。
神经元接收到的总输入值将与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。
理想的激活函数是阶跃函数，它将输入值映射为输出值0或1，显然1对应神经元兴奋，0对应于神经元抑制。然而阶跃函数具有不连续、不光滑等不太好的性质。因此时常使用sigmod挤压函数来作为激活函数。。它把较大范围变化的输入值挤压到（0,1）输出值范围内，因此有时也称为挤压函数。
把许多个神经元按一定层次结构连接起来，就得到了神经网络。
只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，相互代入得到。
感知机与多层网络
感知机由两层神经元组成。输入层接收外界输入信号后传递给输出层，输出层是MP神经元，也称阈值逻辑单元。
感知机能容易地实现逻辑与或非运算。
更一般的，给定训练数据集，权重以及阈值可通过学习得到。
若感知机对训练样例的预测准确，则感知机不发生变化，否则将根据错误的程度进行权重调整。
要注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非常有限。
事实上与或非等问题都是线性可分问题。若两类模式是线性可分的，即存在一个超平面能将其分开。
感知机的学习过程一定会收敛，且求得适当的权向量。否则感知机学习过程将会发生震荡。
要解决非线性可分的问题，需考虑使用多层功能神经元。输出层与输入层之间的一层神经元被称为隐含层，隐含层和输出层神经元都具有激活函数的功能神经元。
更一般的，常见的神经网络是层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为多层前馈神经网络。
其中输入层神经元接收外界输入，隐层和输出层神经元对信号进行加工。最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。只需包含隐层即可称为多层网络，神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。换言之，神经网络学到的东西，蕴含在连接权与阈值中。
误差逆传播算法
多层网络的学习能力比单层感知机强的多。要训练多层网络，简单感知机学习规则显然不够，需要更为强大的学习算法。误差逆传播（BP）算法就是其中杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中，使用神经网络时，大多是在使用BP算法进行训练
值得指出的是，BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络。例如训练递归神经网络。但通常说BP网络时，一般是指用BP算法训练的多层前馈神经网络。
BP算法探秘
BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计。
BP算法基于梯度下降策略，以目标负梯度方向对参数进行调整。
学习率n控制算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。对于学习率即步长非常敏感。
不能保证全局最低，只能是局部最低。
BP算法基本工作流程
对每个训练样例 ，BP算法执行以下操作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直至产生输出层结果；然后计算输出层的误差，再将误差逆向传播至隐层神经元，最后根据隐层神经元误差来对连接权和阈值进行调整。该迭代过程循环进行，直到达到某些停止条件为止。例如训练误差已达到一个很小的值。
BP算法的目标是要最小化训练集D上的累积误差 损失函数
标准BP算法每次仅针对一个训练样例更新连接权和阈值。
累积BP算法和标准BP算法都很常用，一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现抵消现象。因此，为了达到同样的累积误差极小点，标准BP算法往往需要进行更多次数的迭代。
累积BP算法直接针对累积误差最小化，它在读取整个训练集D一遍后才对参数进行更新，一步下降会非常缓慢。这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显。
只需一个包含足够多神经元的隐层，多层前馈网络就能以任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠试错法调整。
正是由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两者策略常用来缓解BP网络的过拟合 。第一种策略是早停：将数据分为训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差。若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。
第二种策略是正则化，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。
全局最小与局部极小
若用E表示神经网络在训练集上的误差，则它显然是关于连接权和阈值的函数。此时，神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得E最小。
显然参数空间内梯度为0的点只要其误差函数值小于邻点的误差函数值，就是局部极小点。但却只会有一个全局最小值。
基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值。每次迭代中。我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索 最优解。若误差函数在当前点的梯度为0则已到局部极小，更新量将为0，这意味着参数的迭代更新在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小 。然而，如果误差具有多个局部极小，则不能保证找到的解是全局最小。对后一种情况，我们称参数陷入了局部极小，这不是我们所希望的。
现实任务中，人们常用一下策略试图跳出局部极小，从而进一步接近全局最小。
以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zereals7.github.io/post/2022-1-24-2022%E5%B9%B41%E6%9C%8822-222857/" />
<meta property="article:published_time" content="2021-06-06T16:23:47+08:00" />
<meta property="article:modified_time" content="2021-06-06T16:23:47+08:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://zereals7.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="Zereal" /></a>
      <h1>Zereal</h1>
      <p>Java coder</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/ZerealS7" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title"></h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jun 6, 2021
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div></div>
    </header>
    <div class="post-content">
      <h2 id="机器学习">【机器学习】</h2>
<p>线性模型形式简单、易于建模。许多功能更为强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。此外，由于w直观表达了各属性在预测中的重要性，因此线性模型有很好的可解释性。</p>
<p><strong>线性回归</strong></p>
<p>对离散属性，若属性间存在序的关系，可通过连续化将其转化为连续值例如二值属性.</p>
<p>均方误差有非常好的几何意义，它对应了常用的欧几里得距离。基于均方误差最小化来进行模型求解的方法称为最小二乘法。</p>
<p>线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线的欧氏距离之和最小。</p>
<p><strong>决策树</strong></p>
<p>决策树是一类常见的机器学习方法，以二分类任务为例，我们希望从给定巡礼那数据集学得一个模型用以对新示例进行分类。一般的，一颗决策树包含一个根结点、若干个内部结点和若干个叶结点。</p>
<p>决策树学习的目的是为了产生一颗泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单而直观的分而治之策略。</p>
<p>显然，决策树的生成是一个递归过程，在决策树算法中，有三种情况会导致递归返回。</p>
<p>、1.当前结点包含的样本全属于同一类别，无需划分。</p>
<p>2.当前属性集为空，或是所有样本在所有属性上取值相同，无法划分。</p>
<p>3.当前结点包含的样本集合为空，不能划分。</p>
<p>一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点的纯度越来越高。</p>
<p>**信得的纯度提升越大。</p>
<p>一般而言，信息增益越大，则意味着使用属性a来进行划分获得的纯度提升越大。</p>
<p>计算出最大的信息增益对应的属性可作为进行划分的。然后再以子节点最大信息增益对应的属性进行划分，最后可以得到决策树。</p>
<p>实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来不利影响，决策树算法不使用信息增益，而是使用增益率来选择最优划分属性。增益率准则对可取值较少的属性有所偏好，算法并不是直接选择增益率最大的候选划分属性，而是使用一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。</p>
<p><strong>基尼指数</strong></p>
<p>决策树使用基尼指数来选择划分属性</p>
<p>数据集D的纯度可用基尼值来度量。</p>
<p>基尼越小数据集D的纯度越高。我们再候选属性集合A中，选择那个使得划分后基尼指数最小的属性作为最优划分属性。</p>
<p><strong>剪枝处理</strong></p>
<p>剪枝是决策树算法对付过拟合的主要手段，再决策树学习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得太好了，以至于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险。</p>
<h2 id="神经网络">【神经网络】</h2>
<p>神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。</p>
<p>神经网络中最基本的是神经元模型。生物神经网络这，每个神经元与其他神经元相连，当它兴奋时，就会向相连的神经元发送化学物质，从而改变这些神经元的电位。如果某神经元电位超过了一个阈值，那么它就会被激活，即兴奋起来，向其他神经元发送化学物质。</p>
<p>神经元接收到的总输入值将与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。</p>
<p>理想的激活函数是阶跃函数，它将输入值映射为输出值0或1，显然1对应神经元兴奋，0对应于神经元抑制。然而阶跃函数具有不连续、不光滑等不太好的性质。因此时常使用sigmod挤压函数来作为激活函数。。它把较大范围变化的输入值挤压到（0,1）输出值范围内，因此有时也称为挤压函数。</p>
<p>把许多个神经元按一定层次结构连接起来，就得到了神经网络。</p>
<p>只需将一个神经网络视为包含了许多参数的数学模型，这个模型是若干个函数，相互代入得到。</p>
<p><strong>感知机与多层网络</strong></p>
<p>感知机由两层神经元组成。输入层接收外界输入信号后传递给输出层，输出层是MP神经元，也称阈值逻辑单元。</p>
<p>感知机能容易地实现逻辑与或非运算。</p>
<p>更一般的，给定训练数据集，权重以及阈值可通过学习得到。</p>
<p>若感知机对训练样例的预测准确，则感知机不发生变化，否则将根据错误的程度进行权重调整。</p>
<p>要注意的是，感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元，其学习能力非常有限。</p>
<p>事实上与或非等问题都是线性可分问题。若两类模式是线性可分的，即存在一个超平面能将其分开。</p>
<p>感知机的学习过程一定会收敛，且求得适当的权向量。否则感知机学习过程将会发生震荡。</p>
<p>要解决非线性可分的问题，需考虑使用多层功能神经元。输出层与输入层之间的一层神经元被称为隐含层，隐含层和输出层神经元都具有激活函数的功能神经元。</p>
<p>更一般的，常见的神经网络是层级结构，每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。这样的神经网络结构通常称为多层前馈神经网络。</p>
<p>其中输入层神经元接收外界输入，隐层和输出层神经元对信号进行加工。最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元。只需包含隐层即可称为多层网络，神经网络的学习过程，就是根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。换言之，神经网络学到的东西，蕴含在连接权与阈值中。</p>
<p><strong>误差逆传播算法</strong></p>
<p>多层网络的学习能力比单层感知机强的多。要训练多层网络，简单感知机学习规则显然不够，需要更为强大的学习算法。误差逆传播（BP）算法就是其中杰出的代表，它是迄今最成功的神经网络学习算法。现实任务中，使用神经网络时，大多是在使用BP算法进行训练</p>
<p>值得指出的是，BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络。例如训练递归神经网络。但通常说BP网络时，一般是指用BP算法训练的多层前馈神经网络。</p>
<p>BP<strong>算法探秘</strong></p>
<p>BP是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计。</p>
<p>BP算法基于梯度下降策略，以目标负梯度方向对参数进行调整。</p>
<p>学习率n控制算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢。对于学习率即步长非常敏感。</p>
<p>不能保证全局最低，只能是局部最低。</p>
<p>BP<strong>算法基本工作流程</strong></p>
<p>对每个训练样例 ，BP算法执行以下操作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直至产生输出层结果；然后计算输出层的误差，再将误差逆向传播至隐层神经元，最后根据隐层神经元误差来对连接权和阈值进行调整。该迭代过程循环进行，直到达到某些停止条件为止。例如训练误差已达到一个很小的值。</p>
<p>BP算法的目标是要最小化训练集D上的累积误差 损失函数</p>
<p>标准BP算法每次仅针对一个训练样例更新连接权和阈值。</p>
<p>累积BP算法和标准BP算法都很常用，一般来说，标准BP算法每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现抵消现象。因此，为了达到同样的累积误差极小点，标准BP算法往往需要进行更多次数的迭代。</p>
<p>累积BP算法直接针对累积误差最小化，它在读取整个训练集D一遍后才对参数进行更新，一步下降会非常缓慢。这时标准BP往往会更快获得较好的解，尤其是在训练集D非常大时更明显。</p>
<p>只需一个包含足够多神经元的隐层，多层前馈网络就能以任意复杂度的连续函数。然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠试错法调整。</p>
<p>正是由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两者策略常用来缓解BP网络的过拟合  。第一种策略是早停：将数据分为训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差。若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。</p>
<p>第二种策略是正则化，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。</p>
<p><strong>全局最小与局部极小</strong></p>
<p>若用E表示神经网络在训练集上的误差，则它显然是关于连接权和阈值的函数。此时，神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得E最小。</p>
<p>显然参数空间内梯度为0的点只要其误差函数值小于邻点的误差函数值，就是局部极小点。但却只会有一个全局最小值。</p>
<p>基于梯度的搜索是使用最为广泛的参数寻优方法。在此类方法中，我们从某些初始解出发，迭代寻找最优参数值。每次迭代中。我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向。例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索 最优解。若误差函数在当前点的梯度为0则已到局部极小，更新量将为0，这意味着参数的迭代更新在此停止。显然，如果误差函数仅有一个局部极小，那么此时找到的局部极小就是全局最小  。然而，如果误差具有多个局部极小，则不能保证找到的解是全局最小。对后一种情况，我们称参数陷入了局部极小，这不是我们所希望的。</p>
<p>现实任务中，人们常用一下策略试图跳出局部极小，从而进一步接近全局最小。</p>
<p>以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。</p>
<p>使用模拟退火技术。模拟退火在每一步都以一定的概率接收比当前更差的结果。从而有助于跳出局部极小，在每步迭代过程中，接收次优解的概率要随着时间的推移而逐渐降低，从而保证算法稳定。</p>
<p>使用随机梯度下降，与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小搜索。</p>
<p>此外遗传算法也常用来训练神经网络以更好地逼近全局最小，需注意的是，上述用于跳出局部极小的技术大多是启发式，理论上尚缺乏保障。</p>
<p><strong>其他常见神经网络</strong></p>
<p>RBF<strong>网络</strong></p>
<p>RBF网络是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。</p>
<p>通常采用两步过程来训练RBF网络：第一步，确定神经元中心c，常用的方式包括随机采样，聚类等；第二步，利用BP算法等来确定参数。</p>
<p>ART<strong>网络</strong></p>
<p>竞争型学习是神经网络中一种常用的无监督学习策略，在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制。这种机制也称胜者通吃原则。</p>
<p>ART网络是竞争型学习的重要代表，该网络由比较层、识别层、识别阈值和重置模块构成。其中比较层负责接收输入样本，并将其传递给识别 层神经元，识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增长以增加新的模式类。</p>
<p>在接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神经元。竞争最简单的方式是，计算输入向量与每个识别层神经元所对应的模式类代表向量之间的距离，距离最小者胜，获胜神经元将向其他识别层神经元发送信号，抑制其激活。若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值，则当前输入样本将被归为该代表向量所属类别。同时网络连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大相似度，从而使该获胜神经元有更大可能获胜；若相似度不大于识别阈值，则重置模块将在识别层增设一个新的神经元，其代表向量就设置为当前输入向量。</p>
<p>显然，识别阈值对ART网络的性能有重要影响，当识别阈值较高时，输入样本将会被分成比较多，比较精细的模式类。而如果识别阈值较低，则会产生比较少，比较粗糙的模式类。</p>
<p>ART较好缓解了竞争型学习中的可塑性-稳定性窘境。可塑性是指神经网络要有学习新知识的能力，而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆，这就使得ART网络具有一个很重要的优点。可进行增量学习或在线学习、</p>
<p>早期ART网络只能处理布尔型输入数据，此后ART发展成了一个算法族，包括能处理实值输入的ART2网络、结合模糊处理的FuzzyART网络，以及可进行监督学习的ARTMAP网络。</p>
<p>SOM<strong>网络</strong></p>
<p>SOM网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中的相似样本点映射到网络输出层中的邻近神经元。</p>
<p>SOM网络中的输出层神经元以矩阵方式排列在二维空间中，每个神经元都拥有一个权向量 ，网络在接收输入向量后，将会确定输出层获胜神经元，它决定了该输入向量在低维空间中的位置。SOM训练目标就是为每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的。</p>
<p>SOM的训练过程很简单；在接收到一个训练样本后，每个输出层神经元会计算该样本与自身携带的权向量之间的距离。距离最近的神经元成为竞争获胜者，称为最佳匹配单元。然后，最佳匹配单元及其邻近神经元的权向量将被调整，以使这些权向量与当前输入样本的距离缩小，这个过程不断迭代，直至收敛。</p>
<p><strong>级联相关网络</strong></p>
<p>一般神经网络模型通常假定网络结构是事先固定的，训练目的是利用训练样本来确定合适的连接权、阈值等参数。与此不同，结构自适应网络则将网络结构也作为学习目标之一。并希望能在训练过程中找到最符合数据特点的网络结构。级联相关网络是结构自适应网络的重要代表。</p>
<p>级联相关网络的训练过程，新的隐结点加入时，红色连接权通过最大化新结构的输出与网络误差之间的相关性来进行训练。</p>
<p>级联相关网络有两个主要成分：级联和相关。级联是指是指建立层次连接的层级结构。在开始训练时，网络只有输入层和输出层，处于最小拓扑结构，随着训练的进行，新的隐层神经元逐渐加入，从而创建起层级结构。当新的隐层神经元加入时，其输入端连接权是冻结固定的。相关是指通过最大化新神经元的输出与网络误差之间的相关性来训练相关的参数。</p>
<p>与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快。但其在数据较小时易陷入过拟合。</p>
<p>Elman<strong>网络</strong></p>
<p>与前馈神经网络不同，递归神经网络允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号。这样的结构与信息反馈过程。使得网络在t时刻的输出状态不仅与t时刻的输入有关，还与t-1时刻的网络状态有关，从而能处理与时间有关的动态变化。</p>
<p>Elman网络是最常用的递归神经网络之一。它的结构与多层前馈网络很相似，但隐层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入、隐层神经元通常采用Sigmoid激活函数，而网络的训练则常通过推广的BP算法进行。</p>
<p>Boltzmann<strong>机</strong></p>
<p>神经网络中有一类模型是为网络状态定义一个能量，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数。Boltzmann机就是一种基于能量的模型，其神经元分为两层：显层与隐层。显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达。Boltzmann机中的神经元都是布尔型的，即只能取0,1两种状态，状态1表示激活，状态0表示抑制。令向量s表示n个神经元的状态，wij表示神经元i与j之间的连接权，状态向量s所对应的Boltzmann机能量定义为如下。</p>
<p>若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将达到Boltzmann分布，此时状态向量s出现的概率将仅由其能量与所有可能状态向量的能力确定。</p>
<p>波尔茨曼机的训练过程就是将每个训练样本是为一个状态向量，使其出现的概率尽可能大，标准的波尔茨曼机是一个全连接图，训练网络的复杂度很高。这使其难以用于解决现实任务。现实中常采用受限波尔茨曼机。它仅保留显层与隐层之间的连接。从而将波尔茨曼机结构由完全图简化为二部图。受限机常用对比散度算法来进行训练。散度算法CD对每个训练样本，先计算出隐层神经元状态的概率分布，然后根据这个概率分布采样，再更新连接权。</p>
<p><strong>深度学习</strong></p>
<p>参数越多的模型复杂度越高。容量越大，这意味着它能完成更复杂的学习任务。但一般情况下，复杂模型的训练效率低，易陷入过拟合，训练数据的大幅度增加。因此，以深度学习为代表的复杂模型开始受到人们的关注。</p>
<p>典型的深度学习模型就是很深层的神经网络，显然对神经网络模型，提高容量的一个简单办法是增加隐层的数目，隐层多路，相应的神经元连接权、阈值等参数就会更多。模型复杂度也可通过单纯增加隐层神经元数目来实现。单隐层的多层前馈网络已具有很强大的学习能力，但从增加模型复杂度的角度来看，增加隐层的数目显然比增加隐层神经元的数目更有效，因为增加隐层数不仅增加了拥有激活函数的神经元的数目，还增加了激活函数嵌套的层数，然而，多隐层神经网络难以直接用经典算法如BP进行训练，因为误差在多隐层内逆传播时，往往会发散而不能收敛到稳定状态。</p>
<p>无监督逐层训练是多隐层网络训练的有效手段，其基本思想是每次训练一层隐结点，训练将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入。这称为预训练，在预训练全部完成后，再对整个网络进行微调训练。例如，在深度信念网络DBN中，每层都是一个受限波尔茨曼机，即整个网络可视为若干个RBM堆叠而得。在使用无监督逐层训练时，这是关于训练样本的RBM模型，可按标准的RBM训练；然后将第一层预训练好的隐结点视为第二层的输入结点，对第二层进行预训练；各层训练完成后，再利用BP算法等对整个网络进行训练。</p>
<p>事实上，预训练+微调的做法可视为将大量参数分组，对每组先找到局部看起来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优。这样就在利用了模型大量参数所提供的自由度的同时，有效的节省了训练开销。</p>
<p>另一种节省训练开销的策略是权共享，即让一组神经元使用相同的连接权。这个策略在卷积神经网络CNN中发挥了重要作用，CNN复合多个卷积层和采样层对输入信号进行加工，然后在连接层实现与输出目标之间的映射。每个卷积层都包含多个特征映射，每个特征映射是一个由多个神经元构成的平面，通过卷积滤波器提取输入的一种特征。比如一个卷积层由6个特征映射构成，每个特征映射是一个神经元阵列。其中每个神经元负责通过卷积滤波器提取局部特征。采用层也叫汇合层，其作用是基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息。采样层有很多特征映射。其中每个神经元与上一层对应特征映射的区域相连。并根据此计算输出。，通过复合卷积层和采样层。CNN将原始图像映射成120维特征向量，最后通过一个由神经元构成的连接层和输出层连接完成识别任务。</p>
<p>CNN可用BP算法进行训练，但在训练中，无论是卷积层还是采样层，其每一组神经元 都是用相同的连接权，从而大幅减少了需要训练的参数数目。</p>
<p>无论是DBN还是CNN，其多隐层堆叠，每层对上一层输出进行处理的机制，可看作是在对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化成与输出目标联系更密切的表示，使得原来仅基于最后一层输出映射难以完成的任务成为可能。换言之，通过多层处理，逐渐将初始的低层特征表示转化为高层特征表示后，用简单模型即可完成复杂的分类等学习任务。由此可见深度学习理解为进行特征学习。</p>
<p>以往机器学习用于现实任务时，描述样本的特征通常需由人类专家来设计。这称为特征工程。众所周知，特征的好坏对泛化性能有至关重要的影响，人类专家设计出好特征也并非易事；特征学习则通过机器学习技术自身来产生好特征。</p>
<p>集成学习的结果通过投票法，即少数服从多数。要获得好的集成，个体学习器应好而不同，即个体学习器要有一定的准确性，即学习器不能太坏，并且要有多样性，即学习器间具有差异。</p>
<p>考虑二分类问题和真实函数f，假定基分类器的错误率为e，即对每个基分类器h。假设集成学习通过简单投票法结合T个基分类器，若有超过半数的基分类器正确，则集成分类就正确。</p>
<p>随着集成中个体分类器数目T的增大，集成的错误率将指数下降，最终趋向于0.</p>
<p>关键假设：基学习器的误差相互独立。在现实任务中，个体学习器是为解决同一个问题训练出来的。它们显然不可能互相独立。在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立。事实上，个体学习器的准确性和多样性本身就存在冲突。一般的，准确性很高之后，要增加多样性就需牺牲准确性。事实上，如何产生并结合好而不同的个体学习器，恰是集成学习研究的核心。</p>
<p>根据个体学习器的生成方式，目前集成学习方法大致可分为两大类。即个体学习器间存在强依赖方法、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法，前者的代表是Boosting，后者的代表是Bagging和随机森林。</p>
<p><strong>Boosting</strong></p>
<p>Boosting 是一族可将弱学习器提升为强学习器的算法。这族算法的工作机制类似：先从初始训练集训练出一个基学习器，在根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注。然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这T个基学习器进行加权结合。</p>
<p>Boosting族算法最著名的代表是AdaBoost</p>
<p>Adaboost算法有多种推导方式，比较容易理解的 是基于加性模型，即基学习器的线性组合来最小化指数损失函数。</p>
<p>若指数损失函数最小化，则分类错误率也将最小化；这说明指数损失函数是分类任务原本01损失函数一致的替代损失函数。由于这个替代函数有更好的数学性质，例如连续可微函数，因此我们用它替代01损失函数作为优化目标。</p>
<p>在AdaBoost算法中，第一个基分类器h1是通过直接将基学习算法用于初始数据分布而得；此后迭代地生成h和A,当基分类器h基于分布D产生后，该基分类器的权重a应使得ah最小化指数损失函数。</p>
<p>Adaboost算法在获得Ht-1之后样本分布将进行调整，使得下一轮基学习器ht能纠正Ht-1的一些错误。理想的Ht能纠正Ht-1的全部错误，即最小化。</p>
<p>理想的Ht将在分布Dt下最小化分类误差，因此弱分类器将基于分布Dt来训练，且针对Dt的分类误差应小于0.5，这在一定程度上类似残差逼近的思想。</p>
<p>Boosting算法要求基学习器能对特定的数据分布进行学习。这可通过重赋权法实施，即在训练过程的每一轮中，根据样本分布为每个训练样本重新赋一个权重。对无法接受带权样本的基学习算法，则可通过重采样法来处理，即在每一轮学习中，根据样本分布对训练集重新进行采样，再用重采样而得的样本集对基学习器进行训练。一般而言，这两种做法没有显著的优劣差别。需注意的是，Boosting算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件，检查当前基分类器是否比随机猜测好，一旦条件不满足，则当前基学习器即被抛弃，且学习过程停止。在此种情况下，初始设置的学习轮数T也许还远未达到，可能导致最终集成中只包含很少的基学习器而性能不佳，若采用重采样法，则可获得重启动机会以避免训练过程过早停止，即在抛弃不满足条件的当前学习器之后，可根据当前分布重新对训练样本进行采样，再基于新的采样结果重新训练出基学习器，从而使得学习过程可以持续到预设的T轮完成。</p>
<p>从偏差-方差分解的角度看，Boosting主要关注降低偏差，因此Boosting能基于泛化性能相对弱的学习器构建出很强的集成。</p>
<p>Bagging<strong>与随机森林</strong></p>
<p>欲得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立，虽然独立在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异。自助采样法：给定一个训练数据集，一种可能的做法是对训练样本进行采样，产生出若干个不同的自己，再从每个数据子集中训练出一个基学习器，这样由于训练数据的不同，我们获得的基学习器可望具有比较大的差异，然而，为获得好的集成，我们同时还希望个体学习器不能太差，如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。为解决这个问题，我们可以考虑使用相互有交叠的采样子集。</p>
<p>Bagging是并行式集成学习方法最著名的代表。其基于自助采样法。给定包含m个样本的数据集，先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现。</p>
<p>照这样，我们可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这就是Bagging的基本流程。在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对回归任务使用简单平均法。若分类预测时出现两个类收到同样票数的情形，则最简单的做法是随机选择一个，也可进一步考察学习器投票的置信度来确定最终胜者。</p>
<p>假定基学习器的计算复杂度为Om，则Bagging的复杂度大致为T，考虑到采样与投票平均过程的复杂度很小，而T通常是一个不太大的常数。因此，训练一个Bagging集成与直接使用基学习算法训练一个学习器的复杂度同阶，这说明Bagging是一个很高效的集成学习算法。。另外与标准Adaboost只适用于二分类任务不同，Bagging能不经修改用于多分类回归等任务。</p>
<p>值得一提的是，自助采样过程还给Bagging带来了另一个优点：由于每个基学习器只使用了初始训练集中约63.2%的样本，剩下约36.8%的样本可用作验证集来对泛化性能进行包外估计。为此需记录每个基学习器所使用的训练样本，不妨令Dt表示ht实际使用的训练样本集，令Hoob表示对样本x的包外预测，即仅考虑那些未使用x训练的基学习器在x上的预测。</p>
<p>事实上，包外样本还有许多其他用途，例如当基学习器是决策树时，可使用包外样本来辅助剪枝，或使用估计决策中各结点的后验概率以辅助对零训练样本的结点的处理；当基学习器是神经网络，可使用包外样本来辅助早期停止以减小过拟合。</p>
<p>以偏差-方差分解的角度看，Bagging主要关注降低方差，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显。我们以基于信息增益划分的决策树为基学习器。</p>
<p><strong>随机森林</strong></p>
<p>随机森林是Bagging 的一个扩展变体，RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树为基学习器构建Bagging集成的基础上，进一步子安决策树的训练过程中引入了随机属性选择。具体来说，传统决策树在选择划分属性时是在当前结点的属性集合中选择一个最优属性。而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含K个属性的自己，然后再从这个子集中选择一个最优属性用于划分。这里的参数k控制了随机性的引入程度：若令k=d，则基决策树的构建与传统决策树相同，若令K=1,则是随机选择一个属性用于划分。</p>
<p>随机森林简单、容易实现、计算开销小。令人惊奇的是，它在很多现实任务中展现出强大的性能，被誉为代表集成学习技术水平的方法。可以看出随机森林对Bagging只做了小改动，但是与Bagging中基学习器的多样性仅通过样本扰动而来不同，随机森林中基学习器的多样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通过个体学习器之间差异度的增加而进一步提升。</p>
<p>随机森林的收敛性与Bagging相似。随机森林的起始性能往往相对较差，特别是在集成中只包含一个基学习器时。这很容易理解，因为通过引入属性扰动，随机森林中个体学习器的性能往往有所降低。然而，随着学习器数目的增加，随机森林中个体学习器的性能往往有所降低，然而，随着个体学习器数目的增加，随机森林通常会收敛到更低的泛化误差。值得一提的是，随机森林的训练效率常优于Bagging,因为在个体决策树的构建过程中，Bagging使用的是确定型决策树，在选择划分属性时，要对结点的所有属性进行考察，而随机森林使用的随机型决策树则只需考察一个属性子集。</p>
<p>学习器结合可能会从三个方面带来好处,首先，从统计的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器则会减小这一风险；第二，从计算的方面来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入糟糕局部极小点的风险，第三，从表示的方面来看，某些学习任务的真实假设可能不在当前可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器则肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学得更好的近似。</p>
<p><strong>平均法</strong></p>
<p>对数值输出，最常见的结合策略是使用平均法。加权平均法在集成学习中具有特别的意义，集成学习中的各种结合方法都可视为其特例或变体。事实上，加权平均法可认为是集成学习研究的基本出发点，对给定的基学习器，不同的集成学习方法可视为通过不同的方式来确定加权平均法中的基学习器权重。</p>
<p>加权平均法的权重一般是从训练数据中学习而得，现实任务中的训练样本通常不充分或存在噪声，这将使学出的权重不完全可靠，尤其是对规模比较大的集成来说，要学习的权重比较多，较容易导致过拟合。因此，实验和应用均显示出，加权平均法未必一定优于简单平均法。一般而言，在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时宜采用简单平均法。</p>
<p><strong>投票法</strong></p>
<p>对分类任务来说，学习器H将从类别标记集合中，预测出一个标记，最常见的结合策略是使用投票法。</p>
<p>绝对多数投票法，即若某标记得票过半数，则预测为该标记；否则拒绝预测。</p>
<p><strong>相对多数投票法</strong></p>
<p>即预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取一个。</p>
<p><strong>加权投票法</strong></p>
<p>标准的绝对多数投票法提供了拒绝预测选项，这在可靠性要求较高的学习任务中是一个很好的机制。但若学习任务要求必须提供预测结果，则绝对多数投票法将退化为相对多数投票法。因此，在不允许拒绝预测的任务中，绝对读书，相对多数投票法统称为多数投票法。</p>
<p>在现实任务中，不同类型个体学习器可能产生不同类型的h值，常见的有：</p>
<p>类标记：若Hi将样本x预测为类别cj则取值为1否则为0，使用类标记的投票也称为硬投票。</p>
<p>类概率：相当于对后验概率P的一个估计，使用类概率的投票也称软投票。</p>
<p>不同类型的hi值不能混用，对一些能在预测出类别标记的同时产生分类置信度的学习器，其分类置信度可转化为类概率使用。若此类值未进行规范化，例如支持向量机的分类间隔值，则必须使用一些技术缩放。等分回归等进行校准后才能作为类概率使用。有趣的是，虽然分类器估计出的类概率值一般都不太准确，但基于类概率进行结合却往往比直接基于类标记进行结合性能更好。需注意的是，若基学习器类型不同，则其类概率值不能直接进行比较；在此种情形下，通常将类概率转化为类标记输出，然后再投票。</p>
<p><strong>学习法</strong></p>
<p>当训练数据很多时，一种更为强大的结合策略是使用学习法，即通过另一个学习器来进行结合。这里我们把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器。Stacking先从初始数据集训练出初级学习器，然后生成一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作样例的输入特征，而初始样本的标记仍被当作样例标记。Stacking的算法描述所示，这里我们假定初级学习器使用不同学习算法产生，即初级集成是异质的。</p>
<p>在训练阶段，次级训练集是利用初级学习器产生的，若直接用初级学习器的训练集来产生次级训练集，则过拟合风险会比较大；因此，一般是通过使用交叉验证法和留一法这样的方式，用训练初级学习器未使用的样本来产生次级学习器的训练样本。</p>
<p>次级学习器的输入属性表示和次级学习算法对Stacking集成的泛化性能有很大影响。有研究表明，将初级学习器的输出类概率作为次级学习器的输入属性，用多响应线性回归作为次级学习算法效果较好，在MLR中使用不同的属性集更佳。</p>
<p>贝叶斯模型平均基于后验概率来为不同模型赋予权重，可视为加权平均法的一种特殊实现，对Stacking和BMA进行了比较，理论上来说，若数据生成模型恰在当前考虑的模型中，且数据噪声很少，则BMA不差Stacking，然而在现实应用中，无法确保数据生成模型一定在当前考虑的模型这，甚至可能难以用当前考虑的模型来进行近似，因此，Stacking通常优于BMA，因为其鲁棒性比BMA更好，而且BMA对模型近似误差非常敏感。</p>
<p><strong>多样性</strong></p>
<p>欲构建泛化能力强的集成，个体学习器应好而不同。现在我们来做一个简单的理论分析。</p>
<p>假定我们用个体学习器通过加权平均法结合产生的集成来完成回归学习任务。对示例x定义学习器hi的分歧为</p>
<p>则集成的分歧是。</p>
<p>显然分歧表征了个体学习器在样本x上不一致性，即在一定程度上反映了个体学习器的多样性。个体学习器hi和集成H的平方误差分别为</p>
<p>E表示个体学习器的加权均值</p>
<p>个体学习器准确性越高、多样性越大，则集成越好，这是误差分歧分解。</p>
<p>现实任务中，很难直接对E-A进行优化，不仅由于它们是定义在整个样本空间上，还由于A不是一个直接操作的多样性度量，它仅在集成构造好之后才能进行估计。此外需注意的是，上面的推导过程只适用于回归学习，难以直接推广到分类学习任务上去。</p>
<p><strong>多样性度量</strong></p>
<p>顾名思义，多样性度量是用于度量集成中个体分类器的多样性，即估算个体学习器的多样化程度，典型做法是考虑个体分类器的两两相似/不相似性。</p>
<p>数据点云的位置越高，则个体分类器准确性越低，点云的位置越靠右，则个体学习器的多样性越小。</p>
<p><strong>多样性增强</strong></p>
<p>在集成学习中需有效地生成多样性大的个体学习器。与简单地直接用初始数据训练出个体学习器相比，如何增强多样性呢？一般思路是在学习过程引入随机性，常见做法主要是对数据样本、输入属性、输出表示、算法参数进行扰动。</p>
<p><strong>数据样本扰动</strong></p>
<p>给定初始数据集，可从中产生出不同的数据子集，再利用不同的数据子集训练出不同的个体学习器。数据样本扰动通常是基于采样法。例如在Bagging中使用自助采样，在AdaBoost中使用序列采样。此类做法简单高效，使用最广。对很多常见的基学习器，例如决策树、神经网络等，训练样本稍加变化就会导致学习器有显著变动，数据样本扰动法对这样的不稳定基学习器很有效；然而，有一些基学习器对数据样本的扰动不敏感，例如线性学习器、支持向量机、朴素贝叶斯、K邻近学习器等，这样的基学习器称为稳定基学习器，对此类基学习器进行集成往往需使用输入属性扰动等其他机制。</p>
<p>训练样本通常由一组属性描述，不同的子空间提供了观察数据的不同视角，显然，从不同子空间训练出的个体学习器必然有所不同。著名的随机子空间算法就依赖于输入属性扰动，该算法从初始属性集中抽取出若干个属性子集，再基于每个属性子集训练一个基学习器。对包含大量冗余属性的数据，在子空间中训练个体学习器不仅能产生多样性大的个体，还会因属性数的减少而大幅节省时间开销，同时，由于冗余属性多，减少一些属性后训练出的个体学习器也不至于太差。若数据只包含少量属性，或者冗余属性很少，则不宜使用输入属性扰动法。</p>
<p><strong>输出表示扰动</strong></p>
<p>此类做法的基本思路是对输出表示进行操纵以增强多样性。可对训练样本的类标记稍作变动，如翻转法，随机改变一些训练样本的标记；也可对输出表示进行转化，如输出调制法，将分类输出转化为回归输出后构建个体学习器；还可将原任务拆解为多个可同时求解的子任务，如ECOC法，利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基学习器。</p>
<p><strong>算法参数扰动</strong></p>
<p>基学习算法一般都有参数需进行设置，例如神经网络的隐层神经元数、初始连接权值等，通过随机设置不同的参数，往往可产生差别较大的个体学习器。例如，负相关法显式通过正则化项来强制个体神经网络使用不同的参数，对参数较少的算法，可通过将其学习过程中某些环节用其他类似方法代替，从而达到扰动的目的，例如可将决策树使用的属性选择机制替换为其他的属性选择机制。值得指出的是，使用单一学习器时通常需使用交叉验证等方法来确定参数值，这事实上已使用不同参数训练出多个学习器，只不过最终仅选择其中一个学习器进行使用，而集成学习则相当于把这些学习器都利用起来；由此也可看出，集成学习技术的实际计算开销，并不比使用单一学习器大很多。</p>
<p>Boosting主要关注降低偏差，而Bagging主要关注降低方差。MultiBoosting方法尝试将二者的优点加以结合。</p>
<p>在集成产生之后再试图通过去除一些个体学习器来获得较小的集成，称为集成修剪。这有助于减小模型的存储开销和预测时间开销。</p>
<p><strong>聚类</strong></p>
<p>在无监督学习中，训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。此类学习任务中研究最多、应用最广的是聚类。</p>
<p>聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个簇。通过这样的划分，每个簇可能对应一些潜在的概率，如浅色瓜，深色瓜，有籽瓜，无籽瓜，甚至本地瓜，外地</p>

    </div>
    <div class="post-footer">
      
    </div>
    <div class="post-comment">
      
      


<span id="/post/2022-1-24-2022%E5%B9%B41%E6%9C%8822-222857/" class="leancloud_visitors" data-flag-title="">
    <span class="post-meta-item-text">文章阅读量 </span>
    <span class="leancloud-visitors-count">1000000</span>
    <p></p>
  </span>
<div id="vcomments"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script type="text/javascript">
  new Valine({
    el: '#vcomments' ,
    appId: 'cScQmclMsD4OOWCclCP1pNsz-gzGzoHsz',
    appKey: 'dtSaHLmdH3J4ICVVInYg9YFM',
    notify:  false ,
  verify:  false ,
  avatar:'mm',
    placeholder: '说点什么吧...',
    visitor:  true 
  });
</script>

    </div>
  </article>

    </main>
  </body>
</html>
